---
title: "HW 06 - Money in US politics"
# author: "Nick Duran"
# date: "`r Sys.Date()`"
editor: 
  markdown: 
    wrap: sentence
---

![](img/sharon-mccutcheon-rItGZ4vquWk-unsplash.jpg){fig-align="center"}

Every election cycle brings its own brand of excitement -- and lots of money.

Political donations are of particular interest to political scientists and other researchers studying politics and voting patterns.

They are also of interest to citizens who want to stay informed of how much money their candidates raise and where that money comes from.

In the United States, *"only American citizens (and immigrants with green cards) can contribute to federal politics, but the American divisions of foreign companies can form political action committees (PACs) and collect contributions from their American employees."*[^hw-06-money-in-politics-1]

In this assignment we will scrape and work with data foreign connected PACs that donate to US political campaigns.

First, we will get data foreign connected PAC contributions in the 2024 election cycle.

Then, you will use a similar approach to get data such contributions from previous years so that we can examine trends over time.

## Getting started

Go to Posit Cloud and find your homework R Markdown document, open it up and adjust the YAML with your information.

Knit the document to make sure it compiles without errors.

## Packages

We'll use the **tidyverse** package for much of the data wrangling and visualization, the **robotstxt** package to check if we're allowed to scrape the data, the **rvest** package for data scraping, and the **scales** package for better formatting of labels on visualizations.

These packages are already installed for you.

You can load them by running the following in your Console:

```{r load-packages}
#| message: false
#| eval: true

library(tidyverse)
library(robotstxt)
library(rvest)
library(scales)
```

```{r}
#| message: false
#| eval: true
#| echo: false

library(kableExtra)
library(here)
```

## Data

This assignment does not come with any prepared datasets.
Instead you'll be scraping the data!

# Exercises

## PART 1: Data collection via web scraping

![](img/opensecrets.png){fig-align="center"}

The data come from [OpenSecrets.org](https://www.opensecrets.org), a *"website tracking the influence of money on U.S. politics, and how that money affects policy and citizens' lives"*.

This website is hosted by The Center for Responsive Politics, which is a nonpartisan, independent nonprofit that *"tracks money in U.S. politics and its effect on elections and public policy."*[^hw-06-money-in-politics-2]

Before getting started, let's check that a bot has permissions to access pages on this domain.

```{r}
#| eval: false
#| warning: true
#| message: false

library(robotstxt)
paths_allowed("https://www.opensecrets.org")
```

Our goal is to scrape data for contributions in all election years Open Secrets has data for.

Since that means repeating a task many times, let's first write a function 

<!-- that works on the first page. -->
<!-- Confirm it works on a few others. -->
<!-- Then iterate it over pages for all years. -->

### Exercise 1

::: callout-important
Complete the following steps (#1-5) in the `scrape-page-pac.R` file in the `scripts` folder of your Posit Cloud project folder for Module 6. Open up this file now as the steps below go hand-in-hand with the starter code already written in `scrape-page-pac.R.` All you need to do is replace the `___` with code you should already know. 
:::

::: callout-important
**CRITICAL:** We are going to do something a bit different here with reading in the web pages. Instead of reading the live URL for each page, you are going to read in a static URL for each page. I have already collected these for you. These static pages are stored in the `static-pages-opensecrets` folder. We can do the scraping exactly as we have in the previous assignments. The major difference is that we are not going to access a site starting with something like "http:\\", instead you are going to access the site as stored as a HTML file. 
:::

-   **STEP #1:** Complete the code for the function called `scrape_pac()`. The goal of the function is to scrape the table from the Open Secrets webpage for foreign-connected PAC contributions in a given year (please take a look at the actual table as it's displayed on the website. You can find the link in the first sidenote; above and to the far right of your screen). This function should:

    - have one input: the static HTML file of a webpage that contains the table
    
    - rename variables scraped, using `snake_case` naming; variables are the table headers
    
    - add a new column to the data frame for `year` using `mutate()` 

::: callout-note
How do you get the year? Well, look at how the HTML files are named in the `static-pages-opensecrets` folder. Do you see how the year is embedded in the filename?

What you want to do is extract out just the year using the `str_sub()` function, where you will extract the characters corresponding to the year from the filename. You will probably want to look at the help for this function to figure out how to so this. 
:::

-   **STEP #2:** Define the static URLs for 2022, 2020, and 2000 contributions. Then, test your function using these URLs as inputs. Does the function seem to do what you expected it to do?

-   **STEP #3:** Construct a vector called `urls` that contains the URLs for each webpage that contains information on foreign-connected PAC contributions for *every other year* starting at 2000 and going up to 2024 (e.g., 2000, 2002, 2004, etc.)

-   **STEP #4:** Map the `scrape_pac()` function over `urls` in a way that will result in a data frame called `pac_all`.

-   **STEP #5:** Write the data frame to a csv file called `pac-all.csv` in the `data` folder.

When youâ€™re done, here is what the first ten rows of your output should look like:

:::callout-important
The contents of the table might not be identical because the content of the web site changes over time, but it should close in terms of formatting.

Also, your variables may or may not look like mine. It all depends on what you named them in **STEP 1**
:::

```{r}
#| eval: true
#| echo: false
#| message: false

pac_all <- read_csv(here("homework/data", "pac-all.csv"))
pac_all[1:10,1:6] %>%
  kbl() %>%
  kable_styling()
```


## PART 2: Data cleaning

::: callout-important
Complete the following set of exercises in the `mod-06-hw.Rmd` starter file in your Posit Cloud project for Module 6. 
:::

In this section we clean the `pac_all` data frame to prepare it for analysis and visualization.

We have two goals in data cleaning:

(1) Separate the `country_parent` into two such that country and parent company appear in different columns for country-level analysis.

(2) Convert contribution amounts in `total`, `dems`, and `repubs` from character strings to numeric values.

The following exercises walk you through how to make these fixes to the data. 

When you're done, here is what the first ten rows of your output should look like:

::: callout-important
The contents of the table might not be identical because the content of the web site changes over time, but it should close in terms of formatting.
:::

```{r}
#| eval: true
#| echo: false
#| message: false

pac_all <- read_csv(here("homework/data", "pac-all.csv"))
pac_all2 <- pac_all %>% separate(country_parent, c("country", "parent"), sep="/", extra = "merge")
pac_all3 <- pac_all2 %>%
  mutate(total = str_remove(total, "\\$"), total = str_remove_all(total, ",")) %>%
  mutate(dems = str_remove(dems, "\\$"), dems = str_remove_all(dems, ",")) %>%
  mutate(repubs = str_remove(repubs, "\\$"), repubs = str_remove_all(repubs, ","))
pac_all3$total <- as.integer(pac_all3$total)
pac_all3$dems <- as.integer(pac_all3$dems)
pac_all3$repubs <- as.integer(pac_all3$repubs)
pac_all3[1:10,1:7] %>%
  kbl() %>%
  kable_styling()
```

---

### Exercise 2

-   In your R Markdown file, load `pac-all.csv` and report its number of observations and variables using inline code.

---

### Exercise 3

-   Use the `separate()` function to separate `country_parent` into `country` and `parent` columns.

Note that country and parent company names are separated by `/` (which will need to be specified in your function) and also note that there are some entries where the `/` sign appears twice and in these cases we want to only split the value at the first occurrence of `/`. This can be accomplished by setting the `extra` argument to `"merge"`, which essentially ignores the second occurrence of `/`, e.g. we want `"Denmark/Novo Nordisk A/S"` to be split into `"Denmark"` and `"Novo Nordisk A/S"`. See the help for `separate()` if you get stuck.
    
-   End your code chunk by printing out the top 10 rows of your data frame. You can use `head()` to do this.

---

### Exercise 4

-   Remove the character strings including "$" and "," in the `total`, `dems`,and `repubs` columns and convert these columns to numeric.

-   End your code chunk by printing out the top 10 rows of your data frame (you can use `head()` to do this).
    
A couple hints to help you out:

(1) The `$` character is a special character so it will need to be escaped.

(2) Some contribution amounts are in the millions (e.g. Anheuser-Busch contributed a total of \$1,510,897 in 2008). In this case we need to remove all occurrences of ",", which we can do by using `str_remove_all()` instead of `str_remove()`.

## PART 3: Data visualization and interpretation

### Exercise 5

-   Create a line plot of total contributions from all foreign-connected PACs in Canada and Mexico over the years.

-   Once you have made the plot, write a brief interpretation of what the plot reveals.

Few hints to help you out:

(1) Filter for only `Canada` and `Mexico`.
(2) Calculate sum of total contributions from PACs for each year for each country by using a sequence of `group_by()` then `summarize()`.
(3) Make a plot of total contributions (y-axis) by year (x-axis) where two lines identified by different colors represent each of Canada and Mexico.

---

### Exercise 6

-   Recreate the following visualization. Note that these are only UK contributions. You will need to make use of functions from the **scales** package for axis labels as well as from **ggplot2**.

-   Once you have made the plot, write a brief interpretation of what the plot reveals. 

<!-- ::: callout-tip -->
::: callout-note
The figure you create might look slightly different than this one if the data on the website has been updated recently. But the title and labels and colors need to be identical. 
:::

```{r fig.fullwidth = TRUE, fig.asp = 0.5}
#| eval: true
#| echo: false
#| message: false

pac_all3_fig2 <- pac_all3 %>% 
  filter(country == "UK") %>%
  group_by(year) %>%
  summarize(total = sum(total), Democrats = sum(dems), Republicans = sum(repubs)) %>%
  pivot_longer(c("Democrats", "Republicans"), names_to = "party")

ggplot(pac_all3_fig2, aes(year, value, color=party)) +
  geom_line(size=1) +
  theme_minimal() +
  labs(title = "Contribution to US politics from UK-Connected PACs",
       subtitle = "By party, over time",
       x = "Year", 
       y = "Amount", 
       color = "Party") +
  scale_y_continuous(labels = dollar_format(scale = 0.000001, suffix = "M")) +
  scale_color_manual(values = c("Democrats" = "blue", "Republicans" = "red")) # Assigning colors to party
  
```

::: callout-note
**SUBMITTING YOUR WORK**

Once you are happy with the final state of your work, change the YAML `output` from `html_output` to `pdf_output.` Now knit the document to produce a final PDF file. Upload the PDF as a Canvas assignment.  
:::

[^hw-06-money-in-politics-1]: Source: [Open Secrets - Foreign Connected PACs](https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs).

[^hw-06-money-in-politics-2]: Source: [Open Secrets - About](https://www.opensecrets.org/about/).




