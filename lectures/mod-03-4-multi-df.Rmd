---
title: "Working with multiple data frames"
subtitle: "<br><br> Behavioral Data Science I in R"
# author: "[datasciencebox.org](https://datasciencebox.org/)"
output:
  xaringan::moon_reader:
    css: ["xaringan-themer.css", "slides.css"]
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightLines: true
      highlightStyle: solarized-light
      countIncrementalSlides: false
---

```{r child = "setup.Rmd"}

# "cast_from": xaringan::inf_mr(cast_from = '../')
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
options(
  dplyr.print_min = 10, 
  dplyr.print_max = 10
  )
```

class: middle

# .hand[We...]

.huge[.green[have]] .hand[multiple data frames]

.huge[.pink[want]] .hand[to bring them together]

???
So far we've worked with a single data frame and we've transformed it using dplyr functions. In this video we're going to work with multiple data frames - particularly on how to combine and them in meaningful ways. 

---

```{r include=FALSE}
professions <- read_csv("mod-03-4-multi-df_files/scientists/professions.csv")
dates <- read_csv("mod-03-4-multi-df_files/scientists/dates.csv")
works <- read_csv("mod-03-4-multi-df_files/scientists/works.csv")
```

## Data: Women in science 

Information on 10 women in science who changed the world

.small[
```{r echo=FALSE}
professions %>% select(name) %>% kable()
```
]

.footnote[
Source: [Discover Magazine](https://www.discovermagazine.com/the-sciences/meet-10-women-in-science-who-changed-the-world)
]

???
The data that we're going to work with comes from discover magazine. They had a article back in March 2020 on 10 women in science who changed the world. Listed here are the names of the 10 women. Now this data on our scientists is organized across three datasheets. In the real world, when collecting data, often you have unique information spread out in this way. 

---

## Inputs

.panelset[

.panel[.panel-name[professions]
```{r}
professions
```
]

.panel[.panel-name[dates]
```{r}
dates
```
]

.panel[.panel-name[works]
```{r}
works
```
]

]

???
one of the datasheets we're working with is called "professions," the second "dates" and the third datasheet is called "works." Lets take a look at what we have in the "professions" datasheet. 

There are 10 rows. Each row has information on each woman's profession. For example, the first column, labeled "name," is the name of the scientist. The first row is Ada Lovelace. In the second column is the scientist's profession. For Lovelace, that is a mathematician. 

Now if we go to the "dates" datasheet, what do we see? First thing to notice is that the first column also contains the name of the scientists, and the column is also labeled "name." Ok, this is consistent with the "professions" datasheet. But what is different is that we now have columns/variables that contain information on the birth and death year of each scientist (and note that West and Doudna are still alive as of this recording so death year is NA). Another big difference is that we only have 8 rows. It looks like we are missing information on two of the scientists from the previous datasheet. Bummer. Now, I could look up this information on Wikipedia and add it here, but what I'm trying to simulate is a real-life situation where you sometimes have missing data. 

And finally, in our third datasheet, "works," we have what each scientist is known for. Notice the first column looks similar to the previous but we have this "known_for" column and nine rows. Someone is missing.

---

## Desired output

```{r echo=FALSE}
professions %>%
  left_join(dates) %>%
  left_join(works)
```

???
What we want to do is combine all the information across the datasets to create a single, complete dataframe. For each of the 10 scientists, we want all the variables together, and if we have missing data for any entry on any variable, we also want that to be marked with an NA (not applicable). Ok, so how do we do it? 

---

## Inputs, reminder

.pull-left[
```{r}
names(professions)
names(dates)
names(works)
```
]
.pull-right[
```{r}
nrow(professions)
nrow(dates)
nrow(works)
```
]

???
The first thing to look for is a common variable across the datasets. On the left I've printed the names of the variables in each of our datasheets. It looks like we have this common variable called "name." Makes sense as "name" corresponds to the names of the scientists who we are collecting information on. The next thing to take note of is which, if any, of our datasheets has the most observations. On the right I've printed out the number of rows. Looks like our "professions" datasheet has the most. Ok, great, armed with this information we can start making some decisions. 

---

class: middle

# Joining data frames

???
And these decisions are concerned with how to start joining the dataframes to get to our desired output. 

---

## Joining data frames

```{r eval=FALSE}
something_join(x, y)
```

- `left_join()`: all rows from x
- `right_join()`: all rows from y
- `full_join()`: all rows from both x and y
- `semi_join()`: all rows from x where there are matching values in y, keeping just columns from x
- `inner_join()`: all rows from x where there are matching values in y, return 
all combination of multiple matches in the case of multiple matches
- `anti_join()`: return all rows from x where there are not matching values in y, never duplicate rows of x
- ...

???
To join dataframes using dplyr functions, we use a set of functions that are always of the format "something_join." So, "left_join," "right_join," full_join, semi_join, and so on. I'm not going through each one right now as I'm going to show you what each does in the upcoming slides. But I do want to draw your attention to the fact that I ended this bullet list with a dot dot dot. These are not all of the join functions dplyr makes available, but they're the ones that we're going to focus on because they're the most common.
 
---

## Setup

For the next few slides...

.pull-left[
```{r echo=FALSE}
x <- tibble(
  id = c(1, 2, 3),
  value_x = c("x1", "x2", "x3")
  )
```
```{r}
x
```
]
.pull-right[
```{r echo=FALSE}
y <- tibble(
  id = c(1, 2, 4),
  value_y = c("y1", "y2", "y4")
  )
```
```{r}
y
```
]

???
Alright, for the next slides - in addition to the women scientists dataframe I showed you - I also have two simple dataframes that I'm going to use to illustrate examples. These are super simple but important. In the first one, that I'm calling "x," it has three observations across two variables. An "ID" variable and, for each observation in "ID," a value, labeled x1, x2, and x3. And in the second dataframe, that I'm calling "y," looks really similar. It also has an "ID" variable, but not the same id levels (here we have a 4 where "x" has a 3). And the associated values are labeled y1, y2, y4.  

---

## `left_join()`

.pull-left[
```{r echo=FALSE, out.width="80%", out.extra ='style="background-color: #FDF6E3"'}
include_graphics("mod-03-4-multi-df_files/left-join.gif")
```
]
.pull-right[
```{r}
left_join(x, y)
```
]

???
Lets do a "left_join" on the x and y dataframes. For the dataframe entered "on the left," which you can see here is "x," check out what happens. The join fundamentally occurs on the common variable across dataframes, which happened to be the first column/variable in both dataframes. For my leftmost dataframe, x, I always keep all the levels of the common column/variable. And from the y dataframe, I bring along all the levels in the common column/variable that were also in x. For the level "4" - that exists in "y" but not in "x," well, it goes bye bye. 

---

## `left_join()`

```{r}
professions %>%
  left_join(dates) #<<
```

???
Now, what if I do the same thing with the scientist data? I want to start with the "professions" dataframe as my "leftmost" - or first entered dataframe - because it has the most complete set of levels for the common column/variable called "name." By doing it this way, I get to keep all the levels, i.e., scientists, found in the professions dataframe when bringing along the "dates" datasheet, which happens to be missing a couple of scientists. The missing data is now designated by NA in my combined datasheet. 

---

## `right_join()`

.pull-left[
```{r echo=FALSE, out.width="80%", out.extra ='style="background-color: #FDF6E3"'}
include_graphics("mod-03-4-multi-df_files/right-join.gif")
```
]
.pull-right[
```{r}
right_join(x, y)
```
]

???
Now what happens if I swap out left_join with right_join? Well, the rightmost dataframe, which is "y," now becomes the reference dataframe. That is, along the common variable between datasets, I keep all the levels within "y," now bringing along the levels in "x" which are the same. What is not the same when comparing y to x, well, it's the level 3, which now goes bye bye. 

---

## `right_join()`


```{r}
professions %>%
  right_join(dates) #<<
```

???
What happens when we do the same thing in the scientist data between "professions" and "dates"? Well, "dates" (our rightmost, therefore baseline, dataframe) only has information on eight of the 10 scientists, so we only pull information from those eight scientists from the "professions" dataframe. 

---

## `full_join()`

.pull-left[
```{r echo=FALSE, out.width="80%", out.extra ='style="background-color: #FDF6E3"'}
include_graphics("mod-03-4-multi-df_files/full-join.gif")
```
]
.pull-right[
```{r}
full_join(x, y)
```
]

???
Now, what does a full_join do? Well, I get to keep all of my rows from both dataframes and wherever I was missing information I just end up with NAs. 

---

## `full_join()`

```{r}
dates %>%
  full_join(works) #<<
```

???
Let me join two of the dataframes from our scientist dataset that, if you remember, are the ones with missing scientists. The "dates" dataframe is missing two scientists - Ada Lovelace and Marie Curie - and the "works" dataframe is missing one scientist - Rosalind Franklin. This is an interesting situation where there are no common missing scientists between datasheets, at least some information exists for each one. When I bring these two dataframes together I get the date information for the eight scientists for whom that information was available, and then I get the known information for Ade Lovelace and Marie Curie from the "works" dataframe. And likewise, even though the "works" dataframe is missing information on Rosalind Franklin, there is still information about her in the "dates" dataframe, which gets included.  

---

## `inner_join()`

.pull-left[
```{r echo=FALSE, out.width="80%", out.extra ='style="background-color: #FDF6E3"'}
include_graphics("mod-03-4-multi-df_files/inner-join.gif")
```
]
.pull-right[
```{r}
inner_join(x, y)
```
]

???
Alright. An inner_join is straightforward as it is the intersection between dataframes, only returning the rows for which we have data from both dataframes. 

---

## `inner_join()`

```{r}
dates %>%
  inner_join(works) #<<
```

???
So when doing this the "dates" and the "works" dataframes, I end up with seven rows, which are the seven scientists that we had complete data for in both the "dates" and "works" dataframes.

---

## `semi_join()`

.pull-left[
```{r echo=FALSE, out.width="80%", out.extra ='style="background-color: #FDF6E3"'}
include_graphics("mod-03-4-multi-df_files/semi-join.gif")
```
]
.pull-right[
```{r}
semi_join(x, y)
```
]

???
And if I want to do a semi-join, this is very similar to a inner join. Except, this time, I am using the information from the second data frame to match up to my first data frame to see which rows to keep but I'm not actually bringing that information in with me. 

---

## `semi_join()`

```{r}
dates %>%
  semi_join(works) #<<
```

???
So if I do a semi-join for our "dates" and "works" dataframe, I again have the rows that are at the intersection of the two data frames, but I didn't bring along the variables from the "works" dataframe. 

---

## `anti_join()`

.pull-left[
```{r echo=FALSE, out.width="80%", out.extra ='style="background-color: #FDF6E3"'}
include_graphics("mod-03-4-multi-df_files/anti-join.gif")
```
]
.pull-right[
```{r}
anti_join(x, y)
```
]

???
And finally, an anti_join. This is basically a subtraction. It gives you the rows in x (the first dataframe entered) that are not in y. 

---

## `anti_join()`

```{r}
dates %>%
  anti_join(works) #<<
```

???
So if I was to do an anti_join, first entering the "dates" dataframe and comparing to the "works" dataframe, well, I end up with the one scientist who is in "dates" but who is not in the "works." And that is good ol' Rosalind Franklin. 

---

## Putting it altogether

```{r}
professions %>%
  left_join(dates) %>%
  left_join(works)
```

???
Putting it all together, to get to my optimal output I showed you at the beginning of this lecture, I would want to start with the "professions" dataframe because I know that one has all of the rows that I need. And then I would want to left_join the "dates" dataframe so that I get the birth and death years for whoever I have that information for. So again, I'm keeping things at 10 rows. And then, I want to left_join the "works" dataframe to get all the columns for the scientists who I happen to have "known_for" information. Voila! So this is how I get to a final, complete dataframe from multiple dataframes.

---

class: middle

# Case study: Student records

???
I'm going to now give you two very short case studies to exemplify other situations where data joins might be relevant. The first one is... 

---

## Student surveys

- Have:
  - Initial survey: survey taken at the beginning of the course
  - Final survey: survey taken at the end of the course
- Want: Info for everyone who took both surveys, those who only took the first survey (dropped the course? failed to take the final survey?), and those who only took the final survey (added the course late? failed to take the initial survey?)

--

```{r include=FALSE}
initial_survey <- read_csv("mod-03-4-multi-df_files/students/survey1.csv")
final_survey <- read_csv("mod-03-4-multi-df_files/students/survey2.csv")
```

.pull-left[
```{r message = FALSE}
initial_survey
```
]
.pull-right[
```{r message = FALSE}
final_survey
```
]

???
Imagine a situation where you ask students to complete an online survey at the beginning of some course. For each student you know their student ID from official records. You also ask them to self-report their names and email addresses. … And then, let’s say you administer the same online survey at the end of the course. Again, for each student you know their student ID from official records. You ask them to self-report their names and email addresses. … In an ideal world, all the people who responded to the initial survey are the same as those who responded to the final survey. But of course, in the real world, some students might have dropped the course after taking the initial survey or just failed to do the final survey – as it appears to be the case with Peter Schmidt and Mark. And some students who took the final survey did not do the initial survey – as with David Friedlander here – who might have added the course late or just failed to do the first survey. In this little example we have a class of very few students. We can just eyeball who did or didn’t do what, but imagine a class of hundreds of students. We need to write some code. 

---

## Student records

.panelset[

.panel[.panel-name[Both surveys]
```{r}
initial_survey %>% 
  inner_join(final_survey, by = "id") #<<
```
]

.panel[.panel-name[Only initial]
```{r}
initial_survey %>% 
  anti_join(final_survey, by = "id") #<<
```
]

.panel[.panel-name[Only final]
```{r}
final_survey %>% 
  anti_join(initial_survey, by = "id") #<<
```
]

]

???
Alright, let’s start by finding those students who took both surveys. How would I build a new dataframe with just these students? If you said, an “inner_join,” then pat yourself on the back. In the code here, I started with the initial survey dataframe, but really, for an inner_join, it doesn’t really matter which dataframe I start with. An inner_join just finds those levels that appear across some common variable in the datasets. Notice I do something different here from the previous examples in that I explicitly tell R that the common variable to compare across is the one called “id.” Why? Because R assumes any variables with the same name between dataframes are the common variables we’re trying to join on. But the initial_survey dataframe and final_survey dataframe have TWO common variables, called “id” and “name.” And we don’t want to join on the “name” variable because none of the levels are the same. But luckily, with “id,” we can map observations between the datasets. And in building a single, merged dataset, R automatically renames the variables that would otherwise have the same name with the suffix “.x” and “.y” to distinguish them.  

Next, let’s say I want to identify those students who took the initial survey but not the second survey. Which of the “something_join” commands should I use? “anti_join” is the winner. Starting with the initial_survey dataframe, this code is essentially saying to find everything in initial_survey that is NOT in the final_survey – and make the comparison based on the common “id” variable between datasets. 

Now let’s say I want to find those students who didn’t take initial survey but took the final survey. Well, we would also use “anti_join” but now entering the dataframes in the opposite direction. The code here says to find everything in final_survey that is NOT in the initial_survey – and make the comparison based on the common “id” variable between datasets.

---

class: middle

# Case study: Grocery sales

???
Alright, for the last quick demonstration where you have data spread across multiple databases and you need to combine into one. This is an example involving grocery sales. But again, to keep things simple, I'm keeping it down to just a couple of customer sales. 

---

## Grocery sales

- Have:
  - Purchases: One row per customer per item, listing purchases they made
  - Prices: One row per item in the store, listing their prices
- Want: Total revenue

--

```{r include=FALSE}
purchases <- read_csv("mod-03-4-multi-df_files/sales/purchases.csv")
prices <- read_csv("mod-03-4-multi-df_files/sales/prices.csv")
```

.pull-left[
```{r message = FALSE}
purchases
```
]
.pull-right[
```{r message = FALSE}
prices
```
]

???
So what I have are purchases where I have a customer_id column, with two customers, labeled "1" and "2." And for each observation, I have what each customer bought. So customer "1" here bought bread, milk, and a banana. In this other dataframe I have the prices for the various items for things that could be bought. What I want to do is calculate the total revenue I've made from my sales in the "purchases" dataframe based on the cost of things in the "prices" dataframe.  

---

## Grocery sales

.panelset[

.panel[.panel-name[Total revenue]
.pull-left[
```{r}
purchases %>% 
  left_join(prices) #<<
```
]
.pull-right[
```{r}
purchases %>% 
  left_join(prices) %>%
  summarise(total_revenue = sum(price)) #<<
```
]
]

.panel[.panel-name[Revenue per customer]

.pull-left[
```{r}
purchases %>% 
  left_join(prices)
```
]
.pull-right[
```{r}
purchases %>% 
  left_join(prices) %>%
  group_by(customer_id) %>% #<<
  summarise(total_revenue = sum(price))
```
]

]

]

???
So how would I go about doing this calculation? In thinking through the logic of my various "something_join" functions, I know that I probably want to use "left_join." Starting with the purchases dataframe (my leftmost dataframe), I keep all the rows in the purchases dataframe and bring over corresponding information from the prices dataframe. Now I can see for each item that was purchased, the price for that item. Next, I can then simply use a summarize function that we learned about earlier. This code sums up all the values in the price colum and so my total revenue is 5 bucks and 75 cents.  

I could also do something like revenue per customer. All I need to do for that is to add a "group by" layer right before the summarize, and now I know how much money was spent by customer id 1 and customer id 2. So in this example, as with all of the examples, I gave you some case studies that exemplify realistic situations where data might live in separate data sets or databases or data frames. 

